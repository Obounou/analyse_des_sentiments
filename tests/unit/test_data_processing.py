import sys
import os
import unittest
import pandas as pd
<<<<<<< HEAD
from io import StringIO

# Ajouter le dossier parent au chemin pour que Python reconnaisse "src" comme un module
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

# Importer les fonctions de traitement des donnÃ©es
from src.data_processing import clean_text, remove_stopwords, tokenize_text, process_reviews

class TestDataProcessing(unittest.TestCase):

    def setUp(self):
        """PrÃ©paration avant chaque test : crÃ©ation d'un DataFrame temporaire."""
        data = {
            "content": [
                "C'est un trÃ¨s bon produit ! ðŸ‘", 
                "Je dÃ©teste ce service...", 
                "Neutre.", 
                "", 
                "Le prix est trop Ã©levÃ©."
            ]
        }
        self.df = pd.DataFrame(data)

    def test_clean_text(self):
        """VÃ©rifie si la fonction clean_text nettoie correctement le texte."""
        cleaned = clean_text("C'est GÃ©nial!!! 123 ðŸ˜Š")
        self.assertEqual(cleaned, "cest genial")

    def test_remove_stopwords(self):
        """VÃ©rifie si la suppression des stopwords fonctionne."""
        text = "this is a simple test with some stopwords"
        cleaned_text = remove_stopwords(text)
        self.assertNotIn("is", cleaned_text)
        self.assertNotIn("a", cleaned_text)
        self.assertNotIn("with", cleaned_text)

    def test_tokenize_text(self):
        """VÃ©rifie si la tokenisation BERT fonctionne correctement."""
        tokens = tokenize_text("This is a test")
        self.assertIsInstance(tokens, list)
        self.assertGreater(len(tokens), 0)

    def test_process_reviews(self):
        """VÃ©rifie si le pipeline de traitement des avis fonctionne."""
        processed_df = process_reviews(self.df)
        self.assertIn("cleaned_content", processed_df.columns)
        self.assertIn("tokenized_content", processed_df.columns)
        self.assertFalse(processed_df["cleaned_content"].isnull().values.any())
        self.assertFalse(processed_df["tokenized_content"].isnull().values.any())

if __name__ == "__main__":
    unittest.main()
=======

# âœ… Ajouter "src" au chemin pour Ã©viter l'erreur ModuleNotFoundError
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../src")))

# âœ… Importer correctement les fonctions depuis src/data_processing.py
from data_processing import clean_text, remove_stopwords, tokenize_text, process_reviews

class TestDataProcessing(unittest.TestCase):
    """ Teste les fonctions de traitement des avis. """

    def test_clean_text(self):
        """ VÃ©rifie que clean_text supprime bien les caractÃ¨res spÃ©ciaux et met en minuscules. """
        text = "C'est gÃ©nial ! Ã‰lÃ©phant & tÃ©lÃ©. 123"
        expected = "cest genial elephant tele"
        self.assertEqual(clean_text(text), expected)

    def test_remove_stopwords(self):
        """ VÃ©rifie que remove_stopwords supprime bien les stopwords. """
        text = "this is a great product with many features"
        expected = "great product many features"  # Suppression des stopwords
        self.assertEqual(remove_stopwords(text), expected)

    def test_tokenize_text(self):
        """ VÃ©rifie que tokenize_text applique correctement le tokenizer BERT. """
        text = "Machine learning is amazing"
        tokens = tokenize_text(text)
        self.assertIsInstance(tokens, list)  # VÃ©rifie que le rÃ©sultat est une liste
        self.assertGreater(len(tokens), 0)   # VÃ©rifie qu'il y a bien des tokens

    def test_process_reviews(self):
        """ VÃ©rifie que process_reviews applique tout le pipeline sur un DataFrame. """
        data = {
            'content': [
                "This is an amazing product!",
                "Worst experience ever. Don't buy it.",
                "Simple, efficient, and useful."
            ]
        }
        df = pd.DataFrame(data)

        # Appliquer le traitement
        processed_df = process_reviews(df)

        # VÃ©rifier que les colonnes sont crÃ©Ã©es
        self.assertIn('cleaned_content', processed_df.columns)
        self.assertIn('tokenized_content', processed_df.columns)

        # VÃ©rifier que les valeurs sont correctes
        self.assertGreater(len(processed_df['cleaned_content'][0]), 0)
        self.assertGreater(len(processed_df['tokenized_content'][0]), 0)

if __name__ == "__main__":
    unittest.main()

>>>>>>> test_data_processing_branche
